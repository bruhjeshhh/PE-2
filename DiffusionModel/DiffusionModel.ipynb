{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkxG1HDwspk2",
        "outputId": "a79c4600-e22e-424d-8655-97bcad33b7d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Directories set up: /content/drive/MyDrive/LeafImageGeneration/dataset, /content/drive/MyDrive/LeafImageGeneration/results\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define project directory\n",
        "project_dir = \"/content/drive/MyDrive/LeafImageGeneration\"\n",
        "dataset_dir = os.path.join(project_dir, \"dataset\")\n",
        "results_dir = os.path.join(project_dir, \"results\")\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "print(f\"‚úÖ Directories set up: {dataset_dir}, {results_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import glob\n",
        "from diffusers import UNet2DModel, DDPMScheduler\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "# ‚úÖ Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "\n",
        "# ‚úÖ Configuration\n",
        "DATASET_PATH = \"/content/drive/MyDrive/LeafImageGeneration/dataset\"\n",
        "SAVE_IMAGE_DIR = \"/content/drive/MyDrive/LeafImageGeneration/results\"\n",
        "IMAGE_SIZE = 128\n",
        "BATCH_SIZE = 8\n",
        "NUM_EPOCHS = 5\n",
        "LEARNING_RATE = 1e-4\n",
        "NUM_TIMESTEPS = 500\n",
        "NUM_IMAGES = 50  # üî• Generate 50 images\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ‚úÖ Ensure dataset exists\n",
        "if not os.path.exists(DATASET_PATH):\n",
        "    raise FileNotFoundError(f\"‚ùå Dataset folder not found: {DATASET_PATH}\")\n",
        "\n",
        "# ‚úÖ Ensure save directory exists\n",
        "os.makedirs(SAVE_IMAGE_DIR, exist_ok=True)\n",
        "\n",
        "# ‚úÖ Apply Transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# ‚úÖ Custom Dataset Loader (No Subfolders Required)\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.image_paths = glob.glob(os.path.join(root_dir, \"*.*\"))\n",
        "        if not self.image_paths:\n",
        "            raise FileNotFoundError(f\"‚ùå No images found in {root_dir}\")\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image  # No class labels needed\n",
        "\n",
        "# ‚úÖ Load dataset\n",
        "def load_dataset(dataset_path, transform, batch_size=8):\n",
        "    dataset = CustomImageDataset(dataset_path, transform=transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    logging.info(f\"‚úÖ Loaded {len(dataset)} images from dataset!\")\n",
        "    return dataloader\n",
        "\n",
        "# ‚úÖ Define Model\n",
        "def create_model():\n",
        "    model = UNet2DModel(\n",
        "        sample_size=IMAGE_SIZE,\n",
        "        in_channels=3,\n",
        "        out_channels=3,\n",
        "        layers_per_block=1,  # Reduce layers\n",
        "        block_out_channels=(64, 128, 256, 512),  # Reduce channels\n",
        "        down_block_types=(\"DownBlock2D\", \"DownBlock2D\", \"DownBlock2D\", \"DownBlock2D\"),\n",
        "        up_block_types=(\"UpBlock2D\", \"UpBlock2D\", \"UpBlock2D\", \"UpBlock2D\")\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# ‚úÖ Training Loop\n",
        "def train_model(model, dataloader, optimizer, scheduler, num_epochs, device):\n",
        "    scaler = torch.cuda.amp.GradScaler()  # Mixed precision\n",
        "    model.to(device, memory_format=torch.channels_last)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        model.train()\n",
        "        for images in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            images = images.to(device, memory_format=torch.channels_last, non_blocking=True)\n",
        "            noise = torch.randn_like(images, device=device)\n",
        "\n",
        "            timesteps = torch.randint(0, NUM_TIMESTEPS, (images.shape[0],), device=device).long()\n",
        "            noisy_images = scheduler.add_noise(images, noise, timesteps)\n",
        "\n",
        "            with torch.cuda.amp.autocast():  # Mixed precision\n",
        "                predicted_noise = model(noisy_images, timesteps)[\"sample\"]\n",
        "                loss = F.mse_loss(predicted_noise, noise)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        torch.cuda.empty_cache()  # Free GPU memory\n",
        "        logging.info(f\"üìâ Epoch [{epoch+1}/{num_epochs}] - Avg Loss: {epoch_loss / len(dataloader):.4f}\")\n",
        "\n",
        "# ‚úÖ Generate Multiple Images After Training\n",
        "def generate_images(model, scheduler, device, num_images):\n",
        "    model.eval()\n",
        "    for i in range(num_images):\n",
        "        with torch.no_grad():  # üî• Reduce memory usage\n",
        "            z = torch.randn((1, 3, IMAGE_SIZE, IMAGE_SIZE), device=device)\n",
        "            for t in reversed(range(NUM_TIMESTEPS)):\n",
        "                z = scheduler.step(model(z, torch.tensor([t], device=device))[\"sample\"], t, z)[\"prev_sample\"]\n",
        "\n",
        "        generated_image = (z.squeeze(0).permute(1, 2, 0).cpu().numpy() + 1) / 2\n",
        "        generated_image = (generated_image * 255).astype(np.uint8)\n",
        "\n",
        "        # ‚úÖ Save Image\n",
        "        save_path = os.path.join(SAVE_IMAGE_DIR, f\"diffusion_output_{i}.png\")\n",
        "        Image.fromarray(generated_image).save(save_path)\n",
        "        logging.info(f\"‚úÖ Image {i+1}/{num_images} saved: {save_path}\")\n",
        "\n",
        "# ‚úÖ Main Function\n",
        "def main():\n",
        "    # Load dataset\n",
        "    dataloader = load_dataset(DATASET_PATH, transform, BATCH_SIZE)\n",
        "\n",
        "    # Create model, scheduler, and optimizer\n",
        "    model = create_model()\n",
        "    scheduler = DDPMScheduler(num_train_timesteps=NUM_TIMESTEPS)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    # Train model\n",
        "    train_model(model, dataloader, optimizer, scheduler, NUM_EPOCHS, DEVICE)\n",
        "\n",
        "    # Generate and save 50 images\n",
        "    generate_images(model, scheduler, DEVICE, NUM_IMAGES)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "vJC8uIUksJQE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}